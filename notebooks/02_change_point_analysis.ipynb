{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Bayesian Change Point Analysis and Insight Generation\n",
    "\n",
    "This notebook implements Bayesian change point detection using PyMC3 to identify structural breaks in Brent oil price time series and correlate them with geopolitical events.\n",
    "\n",
    "## Objectives:\n",
    "1. **Implement Bayesian Change Point Models** using PyMC3\n",
    "2. **Detect Structural Breaks** in oil price time series\n",
    "3. **Correlate Change Points** with compiled events\n",
    "4. **Quantify Event Impacts** with statistical measures\n",
    "5. **Generate Insights** for stakeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not available, if using conda: `conda install gxx`\n",
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n",
      "PyMC version: 5.25.1\n",
      "ArviZ version: 0.22.0\n"
     ]
    }
   ],
   "source": [
    "# Standard data science imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Bayesian modeling\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, t\n",
    "\n",
    "# Time series utilities\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Import our custom modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from analysis.change_point import BayesianChangePointAnalysis\n",
    "from analysis.event_research import EventResearch\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"PyMC version: {pm.__version__}\")\n",
    "print(f\"ArviZ version: {az.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Price data shape: (9011, 5)\n",
      "Events data shape: (29, 9)\n",
      "Date range: 1987-05-20 00:00:00 to 2022-11-14 00:00:00\n",
      "Number of events: 29\n"
     ]
    }
   ],
   "source": [
    "# Load processed data from Task 1\n",
    "data = pd.read_csv('../data/processed/brent_oil_prices_processed.csv', index_col=0)\n",
    "data.index = pd.to_datetime(data.index)\n",
    "\n",
    "# Load event data\n",
    "events = pd.read_csv('../data/processed/major_events.csv')\n",
    "events['date'] = pd.to_datetime(events['date'])\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Price data shape: {data.shape}\")\n",
    "print(f\"Events data shape: {events.shape}\")\n",
    "print(f\"Date range: {data.index.min()} to {data.index.max()}\")\n",
    "print(f\"Number of events: {len(events)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete!\n",
      "Clean data shape: (8981, 5)\n",
      "Log returns statistics:\n",
      "count    8981.000000\n",
      "mean        0.000178\n",
      "std         0.025571\n",
      "min        -0.643699\n",
      "25%        -0.011222\n",
      "50%         0.000395\n",
      "75%         0.012197\n",
      "max         0.412023\n",
      "Name: log_returns, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate log returns for change point analysis\n",
    "data['log_returns'] = np.log(data['price'] / data['price'].shift(1))\n",
    "data['price_change'] = data['price'].pct_change()\n",
    "\n",
    "# Remove NaN values\n",
    "data_clean = data.dropna()\n",
    "\n",
    "print(\"Data preprocessing complete!\")\n",
    "print(f\"Clean data shape: {data_clean.shape}\")\n",
    "print(f\"Log returns statistics:\")\n",
    "print(data_clean['log_returns'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Change Point Analysis initialized!\n",
      "Data points: 8980\n",
      "Events: 29\n",
      "\n",
      "Log returns statistics:\n",
      "Mean: 0.000176\n",
      "Std: 0.025572\n",
      "Min: -0.643699\n",
      "Max: 0.412023\n"
     ]
    }
   ],
   "source": [
    "# Initialize the change point analysis\n",
    "cpa = BayesianChangePointAnalysis(data_clean, events)\n",
    "\n",
    "print(\"Bayesian Change Point Analysis initialized!\")\n",
    "print(f\"Data points: {len(cpa.log_returns)}\")\n",
    "print(f\"Events: {len(events)}\")\n",
    "\n",
    "# Display log returns statistics\n",
    "print(f\"\\nLog returns statistics:\")\n",
    "print(f\"Mean: {cpa.log_returns.mean():.6f}\")\n",
    "print(f\"Std: {cpa.log_returns.std():.6f}\")\n",
    "print(f\"Min: {cpa.log_returns.min():.6f}\")\n",
    "print(f\"Max: {cpa.log_returns.max():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implementing single change point model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TensorVariable cannot be converted to Python integer. Call `.astype(int)` for the symbolic equivalent.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Implement and fit single change point model\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mImplementing single change point model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m single_model = \u001b[43mcpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43msingle_change_point_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_changepoints\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFitting single change point model...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\brent-oil-price-analysis\\notebooks\\../src\\analysis\\change_point.py:84\u001b[39m, in \u001b[36mBayesianChangePointAnalysis.single_change_point_model\u001b[39m\u001b[34m(self, n_changepoints)\u001b[39m\n\u001b[32m     80\u001b[39m     segment_sds = pm.HalfNormal(\u001b[33m'\u001b[39m\u001b[33msegment_sds\u001b[39m\u001b[33m'\u001b[39m, sigma=\u001b[32m1\u001b[39m, shape=n_changepoints + \u001b[32m1\u001b[39m)\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# Likelihood\u001b[39;00m\n\u001b[32m     83\u001b[39m     segment_idx = pm.Deterministic(\u001b[33m'\u001b[39m\u001b[33msegment_idx\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m                                  \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_segment_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchangepoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_data\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     86\u001b[39m     likelihood = pm.Normal(\u001b[33m'\u001b[39m\u001b[33mlikelihood\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     87\u001b[39m                          mu=segment_means[segment_idx], \n\u001b[32m     88\u001b[39m                          sigma=segment_sds[segment_idx], \n\u001b[32m     89\u001b[39m                          observed=\u001b[38;5;28mself\u001b[39m.log_returns)\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\brent-oil-price-analysis\\notebooks\\../src\\analysis\\change_point.py:379\u001b[39m, in \u001b[36mBayesianChangePointAnalysis._get_segment_indices\u001b[39m\u001b[34m(self, changepoints, n_data)\u001b[39m\n\u001b[32m    377\u001b[39m segment_idx = np.zeros(n_data, dtype=\u001b[38;5;28mint\u001b[39m)\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, cp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(changepoints):\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     segment_idx[\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcp\u001b[49m\u001b[43m)\u001b[49m:] = i + \u001b[32m1\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m segment_idx\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\brent-oil-price-analysis\\venv\\Lib\\site-packages\\pytensor\\tensor\\variable.py:43\u001b[39m, in \u001b[36m_tensor_py_operators.__int__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__int__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m     44\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTensorVariable cannot be converted to Python integer. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     45\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCall `.astype(int)` for the symbolic equivalent.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     46\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: TensorVariable cannot be converted to Python integer. Call `.astype(int)` for the symbolic equivalent."
     ]
    }
   ],
   "source": [
    "# Implement and fit single change point model\n",
    "print(\"Implementing single change point model...\")\n",
    "\n",
    "single_model = cpa.single_change_point_model(n_changepoints=1)\n",
    "\n",
    "# Fit the model\n",
    "print(\"Fitting single change point model...\")\n",
    "single_results = cpa.fit_model(single_model, 'single_change_point', n_samples=2000, n_tune=1000)\n",
    "\n",
    "print(\"\\nSingle change point model fitted successfully!\")\n",
    "print(\"\\nModel summary:\")\n",
    "print(single_results['summary'])\n",
    "\n",
    "# Analyze results\n",
    "single_analysis = cpa.analyze_change_points('single_change_point')\n",
    "\n",
    "print(\"\\nSingle Change Point Analysis Results:\")\n",
    "print(f\"Detected change points: {single_analysis['change_points']}\")\n",
    "print(f\"Number of event correlations: {len(single_analysis['event_correlations'])}\")\n",
    "print(f\"Number of impact measures: {len(single_analysis['impact_analysis'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implementing event-correlated change point model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cpa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Implement and fit event-correlated model\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mImplementing event-correlated change point model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m event_model = \u001b[43mcpa\u001b[49m.event_correlated_model()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFitting event-correlated model...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'cpa' is not defined"
     ]
    }
   ],
   "source": [
    "# Implement and fit event-correlated model\n",
    "print(\"Implementing event-correlated change point model...\")\n",
    "\n",
    "event_model = cpa.event_correlated_model()\n",
    "\n",
    "# Fit the model\n",
    "print(\"Fitting event-correlated model...\")\n",
    "event_results = cpa.fit_model(event_model, 'event_correlated', n_samples=2000, n_tune=1000)\n",
    "\n",
    "print(\"\\nEvent-correlated model fitted successfully!\")\n",
    "print(\"\\nModel summary:\")\n",
    "print(event_results['summary'])\n",
    "\n",
    "# Analyze results\n",
    "event_analysis = cpa.analyze_change_points('event_correlated')\n",
    "\n",
    "print(\"\\nEvent-Correlated Analysis Results:\")\n",
    "print(f\"Detected change points: {event_analysis['change_points']}\")\n",
    "print(f\"Number of event correlations: {len(event_analysis['event_correlations'])}\")\n",
    "print(f\"Number of impact measures: {len(event_analysis['impact_analysis'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations for each model\n",
    "print(\"Generating change point visualizations...\")\n",
    "\n",
    "models = ['single_change_point', 'event_correlated']\n",
    "\n",
    "for model_name in models:\n",
    "    if model_name in cpa.results:\n",
    "        print(f\"\\nPlotting results for {model_name}...\")\n",
    "        cpa.plot_results(model_name, f'../docs/{model_name}_analysis.png')\n",
    "\n",
    "# Create interactive visualization\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add price line\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=data_clean.index,\n",
    "    y=data_clean['price'],\n",
    "    mode='lines',\n",
    "    name='Brent Oil Price',\n",
    "    line=dict(color='blue', width=1)\n",
    "))\n",
    "\n",
    "# Add change points from different models\n",
    "colors = ['red', 'green']\n",
    "for i, model_name in enumerate(models):\n",
    "    if model_name in cpa.results:\n",
    "        analysis = cpa.analyze_change_points(model_name)\n",
    "        for cp in analysis['change_points']:\n",
    "            fig.add_vline(x=cp, line_dash=\"dash\", line_color=colors[i], \n",
    "                         annotation_text=f\"{model_name.replace('_', ' ').title()}\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Brent Oil Prices with Detected Change Points',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Price (USD/barrel)',\n",
    "    height=600\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key insights and business implications\n",
    "print(\"Key Insights and Business Implications:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Collect all results\n",
    "all_change_points = []\n",
    "all_correlations = []\n",
    "all_impacts = []\n",
    "\n",
    "for model_name in models:\n",
    "    if model_name in cpa.results:\n",
    "        analysis = cpa.analyze_change_points(model_name)\n",
    "        all_change_points.extend(analysis['change_points'])\n",
    "        all_correlations.extend(analysis['event_correlations'])\n",
    "        all_impacts.extend(analysis['impact_analysis'])\n",
    "\n",
    "# Remove duplicates\n",
    "unique_change_points = list(set(all_change_points))\n",
    "unique_change_points.sort()\n",
    "\n",
    "print(f\"\\n1. CHANGE POINT DETECTION:\")\n",
    "print(f\"   - Total unique change points detected: {len(unique_change_points)}\")\n",
    "print(f\"   - Change point dates: {unique_change_points}\")\n",
    "\n",
    "if all_correlations:\n",
    "    corr_df = pd.DataFrame(all_correlations)\n",
    "    \n",
    "    print(f\"\\n2. EVENT CORRELATION:\")\n",
    "    print(f\"   - Total event correlations: {len(corr_df)}\")\n",
    "    print(f\"   - Average distance to events: {corr_df['distance_days'].mean():.1f} days\")\n",
    "    print(f\"   - Events within 7 days: {len(corr_df[corr_df['distance_days'] <= 7])}\")\n",
    "    print(f\"   - Events within 30 days: {len(corr_df[corr_df['distance_days'] <= 30])}\")\n",
    "\n",
    "if all_impacts:\n",
    "    impact_df = pd.DataFrame(all_impacts)\n",
    "    \n",
    "    print(f\"\\n3. IMPACT QUANTIFICATION:\")\n",
    "    print(f\"   - Average price change: {impact_df['price_change'].mean():.2f}%\")\n",
    "    print(f\"   - Average volatility change: {impact_df['volatility_change'].mean():.2f}%\")\n",
    "    print(f\"   - Largest price increase: {impact_df['price_change'].max():.2f}%\")\n",
    "    print(f\"   - Largest price decrease: {impact_df['price_change'].min():.2f}%\")\n",
    "    \n",
    "    # Statistical significance\n",
    "    t_stat, p_value = stats.ttest_1samp(impact_df['price_change'], 0)\n",
    "    significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "    print(f\"   - Price changes are {significance} (p={p_value:.6f})\")\n",
    "\n",
    "print(f\"\\n4. BUSINESS IMPLICATIONS:\")\n",
    "print(f\"   - Risk Management: Change points indicate regime changes requiring strategy adjustment\")\n",
    "print(f\"   - Trading Strategies: Optimal entry/exit timing around detected change points\")\n",
    "print(f\"   - Policy Planning: Understanding market stability periods for energy security\")\n",
    "print(f\"   - Investment Timing: Structural breaks provide opportunities for portfolio rebalancing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results for further analysis\n",
    "print(\"Saving results...\")\n",
    "\n",
    "# Collect all results\n",
    "task2_results = {}\n",
    "\n",
    "for model_name in models:\n",
    "    if model_name in cpa.results:\n",
    "        analysis = cpa.analyze_change_points(model_name)\n",
    "        task2_results[model_name] = {\n",
    "            'change_points': [cp.strftime('%Y-%m-%d') for cp in analysis['change_points']],\n",
    "            'event_correlations': analysis['event_correlations'],\n",
    "            'impact_analysis': analysis['impact_analysis'],\n",
    "            'model_diagnostics': cpa.results[model_name]['diagnostics']\n",
    "        }\n",
    "\n",
    "# Save to files\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Save as JSON\n",
    "with open('../data/processed/task2_change_point_results.json', 'w') as f:\n",
    "    json.dump(task2_results, f, indent=2, default=str)\n",
    "\n",
    "print(\"Results saved successfully!\")\n",
    "print(f\"- JSON results: ../data/processed/task2_change_point_results.json\")\n",
    "\n",
    "print(\"\\nTask 2: Change Point Modeling and Insight Generation - COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Models implemented: {len(models)}\")\n",
    "print(f\"Total change points detected: {len(unique_change_points)}\")\n",
    "print(f\"Total event correlations: {len(all_correlations)}\")\n",
    "print(f\"Total impact measures: {len(all_impacts)}\")\n",
    "print(\"Ready for Task 3: Interactive Dashboard Development!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
